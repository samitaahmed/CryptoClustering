{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4Zq0HFIiqz8WMlnacVlJh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samitaahmed/CryptoClustering/blob/main/Crypto_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm1aUMYfeF9J",
        "outputId": "d4e2e8c6-5c50-47d9-cea9-e2528e83462f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hvplot\n",
            "  Downloading hvplot-0.8.4-py2.py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bokeh>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (2.4.3)\n",
            "Requirement already satisfied: colorcet>=2 in /usr/local/lib/python3.10/dist-packages (from hvplot) (3.0.1)\n",
            "Requirement already satisfied: holoviews>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.15.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hvplot) (23.1)\n",
            "Requirement already satisfied: panel>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (0.14.4)\n",
            "Requirement already satisfied: param>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hvplot) (1.13.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.0.0->hvplot) (3.1.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.0.0->hvplot) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.0.0->hvplot) (6.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.0.0->hvplot) (6.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=1.0.0->hvplot) (4.7.1)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from colorcet>=2->hvplot) (0.5.0)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.11.0->hvplot) (2.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->hvplot) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->hvplot) (2022.7.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=0.11.0->hvplot) (3.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=0.11.0->hvplot) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=0.11.0->hvplot) (4.65.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=0.11.0->hvplot) (6.0.0)\n",
            "Requirement already satisfied: setuptools>=42 in /usr/local/lib/python3.10/dist-packages (from panel>=0.11.0->hvplot) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=1.0.0->hvplot) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->hvplot) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=0.11.0->hvplot) (0.5.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.11.0->hvplot) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.11.0->hvplot) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.11.0->hvplot) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=0.11.0->hvplot) (3.4)\n",
            "Installing collected packages: hvplot\n",
            "Successfully installed hvplot-0.8.4\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries and dependencies\n",
        "import pandas as pd\n",
        "!pip install hvplot\n",
        "import hvplot.pandas\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into a Pandas DataFrame\n",
        "df_market_data = pd.read_csv(\n",
        "    \"Resources/crypto_market_data.csv\",\n",
        "    index_col=\"coin_id\")\n",
        "\n",
        "# Display sample data\n",
        "df_market_data.head(40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "EQZjR8WGeZO4",
        "outputId": "dc68b62c-813a-4a1c-ab18-bb87edb5feae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-637d345b8e5f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the data into a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df_market_data = pd.read_csv(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Resources/crypto_market_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     index_col=\"coin_id\")\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resources/crypto_market_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate summary statistics\n",
        "df_market_data.describe()"
      ],
      "metadata": {
        "id": "WL5QgRHledGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot your data to see what's in your DataFrame\n",
        "df_market_data.hvplot.line(\n",
        "    width=800,\n",
        "    height=400,\n",
        "    rot=90\n",
        ")"
      ],
      "metadata": {
        "id": "t2NleI3VefKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the `StandardScaler()` module from scikit-learn to normalize the data from the CSV file\n",
        "\n",
        "df_market_data_scaled = StandardScaler().fit_transform(df_market_data[['price_change_percentage_24h','price_change_percentage_7d','price_change_percentage_14d','price_change_percentage_30d','price_change_percentage_60d','price_change_percentage_200d','price_change_percentage_1y']])\n",
        "# Create a DataFrame with the scaled data\n",
        "df_market_data_scaled = pd.DataFrame(df_market_data_scaled,columns=['price_change_percentage_24h','price_change_percentage_7d','price_change_percentage_14d','price_change_percentage_30d','price_change_percentage_60d','price_change_percentage_200d','price_change_percentage_1y'])\n"
      ],
      "metadata": {
        "id": "JYoVa8N1eheT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the crypto names from the original data\n",
        "crypto_name_index = df_market_data.index\n",
        "\n",
        "# Set the coinid column as index\n",
        "df_market_data_scaled.index = crypto_name_index\n",
        "\n",
        "# Display sample data\n",
        "df_market_data_scaled"
      ],
      "metadata": {
        "id": "zwJXt3mPelIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crypto_name_index"
      ],
      "metadata": {
        "id": "L_oGBrJ4eneW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list with the number of k-values from 1 to 11\n",
        "\n",
        "k = list(range(1,11))\n",
        "k"
      ],
      "metadata": {
        "id": "2lCJ3Worep_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store the inertia values\n",
        "\n",
        "inertia =[]\n",
        "# Create a for loop to compute the inertia with each possible value of k\n",
        "for i in k:\n",
        "    k_model = KMeans(n_clusters = i,random_state=  1)\n",
        "    k_model.fit(df_market_data_scaled)\n",
        "    inertia.append(k_model.inertia_)\n",
        "# Inside the loop:\n",
        "# 1. Create a KMeans model using the loop counter for the n_clusters\n",
        "# 2. Fit the model to the data using `df_market_data_scaled`\n",
        "# 3. Append the model.inertia_ to the inertia list"
      ],
      "metadata": {
        "id": "qGlKES_Rer86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the data to plot the Elbow curve\n",
        "elbow_data = {\"K\": k,\"Inertia\": inertia}\n",
        "df_elbow_scaled = pd.DataFrame(elbow_data)\n",
        "\n",
        "# Create a DataFrame with the data to plot the Elbow curve\n",
        "df_elbow_scaled.head()"
      ],
      "metadata": {
        "id": "HtzhqOtneur1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a line chart with all the inertia values computed with\n",
        "elbow_plot_orginal = df_elbow_scaled.hvplot.line(\n",
        "    x=\"K\",\n",
        "    y=\"Inertia\",\n",
        "    title=\"Elbow Curve\",\n",
        "    xticks=k)\n",
        "df_elbow_scaled.hvplot.line(\n",
        "    x=\"K\",\n",
        "    y=\"Inertia\",\n",
        "    title=\"Elbow Curve\",\n",
        "    xticks=k)\n",
        "# the different values of k to visually identify the optimal value for k.\n"
      ],
      "metadata": {
        "id": "vhsjmDmvexft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Answer the following question:\n",
        "\n",
        "**Question:** What is the best value for `k`?\n",
        "\n",
        "**Answer: the best value for K would be 4 where the marginal benefit of additional cluster (K) provides least intertia**"
      ],
      "metadata": {
        "id": "Rj3h1-JFe0wA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-vdzZvwje34z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Cluster Cryptocurrencies with K-means Using the Original Data"
      ],
      "metadata": {
        "id": "_AQKekKwe62z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the K-Means model using the best value for k\n",
        "model = KMeans(n_clusters= 4,random_state=1)"
      ],
      "metadata": {
        "id": "J9QMDqjme80O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the K-Means model using the scaled data\n",
        "model.fit(df_market_data_scaled)"
      ],
      "metadata": {
        "id": "iCK5WEW1e-hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the clusters to group the cryptocurrencies using the scaled data\n",
        "k_lower = model.predict(df_market_data_scaled)\n",
        "\n",
        "# Print the resulting array of cluster values.\n",
        "k_lower"
      ],
      "metadata": {
        "id": "DqPHzQ4RfAfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame\n",
        "df_market_data_scaled_prediction = df_market_data_scaled.copy()"
      ],
      "metadata": {
        "id": "820SipHOfCUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column to the DataFrame with the predicted clusters\n",
        "df_market_data_scaled_prediction['cluster_lower']=k_lower\n",
        "\n",
        "# Display sample data\n",
        "df_market_data_scaled_prediction.head()"
      ],
      "metadata": {
        "id": "CbeFdE6OfELp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot using hvPlot by setting\n",
        "# `x=\"price_change_percentage_24h\"` and `y=\"price_change_percentage_7d\"`.\n",
        "# Color the graph points with the labels found using K-Means and\n",
        "# add the crypto name in the `hover_cols` parameter to identify\n",
        "# the cryptocurrency represented by each data point.\n",
        "cluster_plot_original =  df_market_data_scaled_prediction.hvplot.scatter(\n",
        "    x=\"price_change_percentage_24h\",\n",
        "    y=\"price_change_percentage_7d\",\n",
        "    by=\"cluster_lower\",\n",
        "    hover_cols =\"coin_id\"\n",
        "    ).opts(yformatter = \"%.0f\")\n",
        "\n",
        "df_market_data_scaled_prediction.hvplot.scatter(\n",
        "    x=\"price_change_percentage_24h\",\n",
        "    y=\"price_change_percentage_7d\",\n",
        "    by=\"cluster_lower\",\n",
        "    hover_cols =\"coin_id\"\n",
        "    ).opts(yformatter = \"%.0f\")"
      ],
      "metadata": {
        "id": "zHI-XkDrfGEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TSg5dezwfIrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Optimize Clusters with Principal Component Analysis."
      ],
      "metadata": {
        "id": "kcXI89OkfLHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PCA model instance and set `n_components=3`.\n",
        "\n",
        "pca = PCA(n_components=3)"
      ],
      "metadata": {
        "id": "-VdCvEXffOMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the PCA model with `fit_transform` to reduce to\n",
        "# three principal components.\n",
        "market_data_pca = pca.fit_transform(df_market_data_scaled)\n",
        "# View the first five rows of the DataFrame.\n",
        "market_data_pca[:5]"
      ],
      "metadata": {
        "id": "IR0jnpbYfPkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the explained variance to determine how much information\n",
        "# can be attributed to each principal component.\n",
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "B-V-592CfRSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Answer the following question:\n",
        "\n",
        "**Question:** What is the total explained variance of the three principal components?\n",
        "\n",
        "**Answer: about 88% of the total variance is condensed into the 3 PCA variables**"
      ],
      "metadata": {
        "id": "0pXL-BuBfUSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame with the PCA data.\n",
        "df_market_data_pca = pd.DataFrame(market_data_pca,columns = ['PCA1','PCA2','PCA3'])\n",
        "\n",
        "# Creating a DataFrame with the PCA data\n",
        "\n",
        "# Copy the crypto names from the original data\n",
        "df_market_data_pca.index = crypto_name_index\n",
        "\n",
        "# Set the coinid column as index\n",
        "\n",
        "\n",
        "# Display sample data\n",
        "df_market_data_pca"
      ],
      "metadata": {
        "id": "G1NVA02hfWwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "9b86xad8fYzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list with the number of k-values from 1 to 11\n",
        "k = list(range(1,11))"
      ],
      "metadata": {
        "id": "fQhsUmQBfb_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store the inertia values\n",
        "inertia=[]\n",
        "\n",
        "# Create a for loop to compute the inertia with each possible value of k\n",
        "\n",
        "for i in k:\n",
        "    k_model = KMeans(n_clusters=i,random_state=1)\n",
        "    k_model.fit(df_market_data_pca)\n",
        "    inertia.append(k_model.inertia_)\n",
        "# Inside the loop:\n",
        "# 1. Create a KMeans model using the loop counter for the n_clusters\n",
        "# 2. Fit the model to the data using `df_market_data_pca`\n",
        "# 3. Append the model.inertia_ to the inertia list\n"
      ],
      "metadata": {
        "id": "koL4FoVXfd1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with the data to plot the Elbow curve\n",
        "elbow_data = {\"k\":k,\"inertia\":inertia}\n",
        "df_elbow = pd.DataFrame(elbow_data)\n",
        "# Create a DataFrame with the data to plot the Elbow curve\n",
        "df_elbow.head()"
      ],
      "metadata": {
        "id": "PaodlY1KfgGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a line chart with all the inertia values computed with\n",
        "# the different values of k to visually identify the optimal value for k.\n",
        "elbow_pca = df_elbow.hvplot.line(\n",
        "    x=\"k\",\n",
        "    y=\"inertia\",\n",
        "    title=\"Elbow Curve\",\n",
        "    xticks=k\n",
        ")\n",
        "df_elbow.hvplot.line(\n",
        "    x=\"k\",\n",
        "    y=\"inertia\",\n",
        "    title=\"Elbow Curve\",\n",
        "    xticks=k\n",
        ")"
      ],
      "metadata": {
        "id": "u03TBatffiJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Answer the following questions:\n",
        "\n",
        "* **Question:** What is the best value for `k` when using the PCA data?\n",
        "\n",
        "  * **Answer: the best value for K is 4 using the PCA data**\n",
        "\n",
        "\n",
        "* **Question:** Does it differ from the best k value found using the original data?\n",
        "\n",
        "  * **Answer: no it doesn't differ from the best K found using the original data**"
      ],
      "metadata": {
        "id": "ylg35e_MfkH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Cluster Cryptocurrencies with K-means Using the PCA Data"
      ],
      "metadata": {
        "id": "oauMdEA9fmRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the K-Means model using the best value for k\n",
        "mdoel = KMeans(n_clusters=4,random_state=1)"
      ],
      "metadata": {
        "id": "TxoYgYFTfoXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the K-Means model using the PCA data\n",
        "model.fit(df_market_data_pca)"
      ],
      "metadata": {
        "id": "7QXkT1CVfp8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the clusters to group the cryptocurrencies using the PCA data\n",
        "k_3 = model.predict(df_market_data_pca)\n",
        "# Print the resulting array of cluster values.\n",
        "k_3"
      ],
      "metadata": {
        "id": "j8ABGTGifr3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a copy of the DataFrame with the PCA data\n",
        "df_market_data_pca_predict = df_market_data_pca.copy()\n",
        "\n",
        "# Add a new column to the DataFrame with the predicted clusters\n",
        "df_market_data_pca_predict['market_segment'] = k_3\n",
        "\n",
        "# Display sample data\n",
        "df_market_data_pca_predict"
      ],
      "metadata": {
        "id": "kXX9GHI9fuWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot using hvPlot by setting\n",
        "# `x=\"PC1\"` and `y=\"PC2\"`.\n",
        "# Color the graph points with the labels found using K-Means and\n",
        "# add the crypto name in the `hover_cols` parameter to identify\n",
        "# the cryptocurrency represented by each data point.\n",
        "cluster_pca = df_market_data_pca_predict.hvplot.scatter(\n",
        "    x=\"PCA1\",\n",
        "    y=\"PCA2\",\n",
        "    by=\"market_segment\"\n",
        ")\n",
        "df_market_data_pca_predict.hvplot.scatter(\n",
        "    x=\"PCA1\",\n",
        "    y=\"PCA2\",\n",
        "    by=\"market_segment\"\n",
        ")"
      ],
      "metadata": {
        "id": "eDNIqU6Mfwrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Visualize and Compare the Results\n",
        "\n",
        "In this section, you will visually analyze the cluster analysis results by contrasting the outcome with and without using the optimization techniques."
      ],
      "metadata": {
        "id": "Zy3oI3xPfzV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Composite plot to contrast the Elbow curves\n",
        "composit_elbow = elbow_pca + elbow_plot_orginal\n",
        "composit_elbow"
      ],
      "metadata": {
        "id": "rXz-sZdof36u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Composite plot to contrast the clusters\n",
        "composit_cluster = cluster_pca + cluster_plot_original\n",
        "composit_cluster"
      ],
      "metadata": {
        "id": "YeYh16pNf5fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Answer the following question:\n",
        "\n",
        "  * **Question:** After visually analyzing the cluster analysis results, what is the impact of using fewer features to cluster the data using K-Means?\n",
        "\n",
        "  * **Answer: in terms of elbow curve the K means resulted the same number of segments, however, from cluster analysis we can see that the clusters are clearly distinguisible using fewer deatures to clusters ( original vs PCA clusert graph) **"
      ],
      "metadata": {
        "id": "bDkPJJbSf9ZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}